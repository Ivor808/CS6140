{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 1 Abalone Data Set\n",
    "### Created By: Ivor Zalud\n",
    "\n",
    "## The Problem\n",
    "I want to predict the age of an Abalone given a set of physical features. These features are: Length, Diameter, Height, Whole_weight, Shucked_weight, Viscera_weight, Shell_weight, and Rings. Age is given by +1.5 to the rings. Thus the features excluding rings will be used to predict rings.\n",
    "\n",
    "## The Data\n",
    "Data for this is provided by UC Irvine [here](archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data). The set includes ~41k rows of data describing physical features of Abalone. The feature set is described above.\n",
    "\n",
    "## Methods\n",
    "* Gradient-Boosted Trees as our multi-class classifier\n",
    "* Stochastic Gradient Descent as our linear regression\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing python modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gradient-Boosted Trees\n",
    "***\n",
    "### - **Regularization**: Scikit outlines it well [here](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regularization.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regularization-py) the optimal regularization methods. We'll use shrinkage and subamsple < 1.0 to produce a more accurate model. This is a result of reducing the variance via bagging\n",
    "### - **Loss function**: Deviance (default for scikit) which will use logistic regressions loss function. We want to minimize this loss function\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load the data\n",
    "\n",
    "### Data corrections:\n",
    "1. Map Sex to numeric value for use in our model\n",
    "    - M -> 0\n",
    "    - F -> 1\n",
    "    - I -> 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "source": [
    "df_train = pd.read_csv('Data/abalone.data')\n",
    "df_train['Sex'] = df_train['Sex'].map({'M': 0, 'F': 1, 'I': 2})\n",
    "## Drop rows that contain only one instance of Ring values, y values need at least two instances for the model.\n",
    "df_train = df_train[~df_train['Rings'].isin([1,26,29,2,25])]\n",
    "\n",
    "df_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4172 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       0   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       0   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       1   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       0   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       2   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    1   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    0   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    0   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    1   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    0   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4172 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 406
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Split the data set into a training and test set\n",
    "### Also split columns into the x and y variables\n",
    "### We adopt a 70/30 split for training vs test as the data set is small"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "source": [
    "## Define our indepedent and dependant variables\n",
    "data_column_names = [column for column in df_train.columns if column not in ['Rings']]\n",
    "x = df_train.loc[:, data_column_names]\n",
    "y = df_train.loc[:,'Rings']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=13)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Create the Gradient-boosted Trees Model and fit with the training data\n",
    "Future studies would benefit from a better splitting strategy of stratified k folds."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "source": [
    "GBT = make_pipeline(StandardScaler(), GradientBoostingClassifier(n_estimators=5000,\n",
    "                                       learning_rate=0.01,\n",
    "                                       max_depth=3,\n",
    "                                       subsample=0.5,\n",
    "                                       validation_fraction=0.1,\n",
    "                                       n_iter_no_change=20,\n",
    "                                       max_features='log2'\n",
    "                                      )).fit(x_train,y_train)\n",
    "\n",
    "GBT.score(x_test,y_test)\n",
    "\n",
    "predictions = GBT.predict(x_test)\n",
    "print(classification_report(y_test, predictions))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.57      0.55      0.56        22\n",
      "           5       0.31      0.36      0.33        33\n",
      "           6       0.37      0.26      0.30        88\n",
      "           7       0.35      0.42      0.38       134\n",
      "           8       0.32      0.40      0.35       159\n",
      "           9       0.23      0.41      0.30       180\n",
      "          10       0.23      0.31      0.26       177\n",
      "          11       0.26      0.30      0.28       142\n",
      "          12       0.08      0.01      0.02        83\n",
      "          13       0.08      0.02      0.03        66\n",
      "          14       0.00      0.00      0.00        44\n",
      "          15       0.00      0.00      0.00        36\n",
      "          16       0.38      0.11      0.17        28\n",
      "          17       0.20      0.05      0.08        19\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.00      0.00      0.00        10\n",
      "          20       0.17      0.11      0.13         9\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.27      1252\n",
      "   macro avg       0.16      0.15      0.15      1252\n",
      "weighted avg       0.24      0.27      0.25      1252\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/Ivor/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Ivor/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Ivor/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Ivor/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Ivor/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/Ivor/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "\n",
    "Generally, the model works poorly at classifing rings. A drawback is our data set size is small at 41k rows. The low f1 score could be due to the small sample size and the small feature set. Adjusting the hyperparameters yielded minimal increases in performance. Future studies would benefit from increasing the sample size and increasing the number of features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stochastic Gradient Descent Regressor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Regularize, run, and fit the model\n",
    "### We already split the data into the training and test set which well use here.\n",
    "\n",
    "### We use scikit-learn's pipeline to scale the data as SGD is sensitive to feature scaling.\n",
    "### -  **Regularization:** L2 - Default of SGD Regressor in Scikit learn. Well keep L2 since we have a low amount of features and do not want to shrink any coefficients to zero.\n",
    "### -  **Loss Function:** Squared error - I want to be sensititve to any outliers in the data.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "reg_predictions = reg.predict(x_test)\n",
    "\n",
    "## Prettier the data to compare actual vs prediction of the first 6 items.\n",
    "i = 0\n",
    "pred_arr = []\n",
    "actual_arr = []\n",
    "for pred in reg_predictions:\n",
    "    pred_arr.append(pred)\n",
    "    i += 1\n",
    "    if i > 6:\n",
    "        break\n",
    "print(\"-----------------------------------------------------\")\n",
    "i = 0\n",
    "for act in y_test:\n",
    "    actual_arr.append(act)\n",
    "    i += 1\n",
    "    if i > 6:\n",
    "        break\n",
    "\n",
    "for x in range(6):\n",
    "    print(\"Actual: \" + str(actual_arr[x]) + \" - Prediction: \" + str(pred_arr[x]))\n",
    "\n",
    "\n",
    "print(\"Score: \" + str(reg.score(x_test, y_test)))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-----------------------------------------------------\n",
      "Actual: 13 - Prediction: 11.208360371575337\n",
      "Actual: 4 - Prediction: 4.988653657792025\n",
      "Actual: 12 - Prediction: 10.620439910418026\n",
      "Actual: 17 - Prediction: 9.548780130785246\n",
      "Actual: 12 - Prediction: 9.809014246907697\n",
      "Actual: 7 - Prediction: 7.746276350121907\n",
      "Score: 0.5743626953677827\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "\n",
    "Similar to the boosted trees, the SGD works fairly poor. Again, this is likely due to the sample and feature set size. To improve the scores, more data and features need to be collected. If one needs a general idea of ring count, the SGD regressor would likely be their best option of the two."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2534124e6b5484b07d693069707edd7e20e1e4151164c7fbebaefa7e2b3a2be4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('tf2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}