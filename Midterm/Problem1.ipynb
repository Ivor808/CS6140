{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 Abalone Data Set\n",
    "### Created By: Ivor Zalud\n",
    "\n",
    "## The Problem\n",
    "I want to predict the age of an Abalone given a set of physical features. These features are: Length, Diameter, Height, Whole_weight, Shucked_weight, Viscera_weight, Shell_weight, and Rings. Age is given by +1.5 to the rings. Thus the features excluding rings will be used to predict rings.\n",
    "\n",
    "## The Data\n",
    "Data for this is provided by UC Irvine [here](archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data). The set includes ~41k rows of data describing physical features of Abalone. The feature set is described above.\n",
    "\n",
    "## Methods\n",
    "* Gradient-Boosted Trees as our multi-class classifier\n",
    "* Stochastic Gradient Descent as our linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosted Trees\n",
    "\n",
    "### - **Regularization**: Scikit outlines it well [here](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regularization.html#sphx-glr-auto-examples-ensemble-plot-gradient-boosting-regularization-py) the optimal regularization methods. We'll use shrinkage and subamsple < 1.0 to produce a more accurate model. This is a result of reducing the variance via bagging\n",
    "### - **Loss function**: Deviance (default for scikit) which will use logistic regressions loss function. We want to minimize this loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "### Data corrections:\n",
    "1. Map Sex to numeric value for use in our model\n",
    "    - M -> 0\n",
    "    - F -> 1\n",
    "    - I -> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole_weight</th>\n",
       "      <th>Shucked_weight</th>\n",
       "      <th>Viscera_weight</th>\n",
       "      <th>Shell_weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4172 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole_weight  Shucked_weight  \\\n",
       "0       0   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       0   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       1   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       0   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       2   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    1   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    0   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    0   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    1   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    0   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera_weight  Shell_weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4172 rows x 9 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('Data/abalone.data')\n",
    "df_train['Sex'] = df_train['Sex'].map({'M': 0, 'F': 1, 'I': 2})\n",
    "## Drop rows that contain only one instance of Ring values, y values need at least two instances for the model.\n",
    "df_train = df_train[~df_train['Rings'].isin([1,26,29,2,25])]\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data set into a training and test set\n",
    "### Also split columns into the x and y variables\n",
    "### We adopt a 80/20 split for training vs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define our indepedent and dependant variables\n",
    "data_column_names = [column for column in df_train.columns]\n",
    "x = df_train.loc[:, data_column_names]\n",
    "y = df_train.loc[:,'Rings']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the Gradient-boosted Trees Model and fit with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lates\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\base.py:441: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex' 'Length' 'Diameter' 'Height' 'Whole_weight' 'Shucked_weight'\n",
      " 'Viscera_weight' 'Shell_weight' 'Rings']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00        14\n",
      "           6       1.00      1.00      1.00        53\n",
      "           7       1.00      1.00      1.00        68\n",
      "           8       1.00      1.00      1.00       119\n",
      "           9       1.00      1.00      1.00       138\n",
      "          10       1.00      1.00      1.00       138\n",
      "          11       1.00      1.00      1.00       106\n",
      "          12       1.00      1.00      1.00        49\n",
      "          13       1.00      1.00      1.00        41\n",
      "          14       1.00      1.00      1.00        24\n",
      "          15       1.00      1.00      1.00        17\n",
      "          16       0.93      0.93      0.93        15\n",
      "          17       1.00      1.00      1.00        17\n",
      "          18       1.00      1.00      1.00        13\n",
      "          19       1.00      1.00      1.00         3\n",
      "          20       1.00      1.00      1.00         1\n",
      "          21       0.67      1.00      0.80         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.50      0.50      0.50         2\n",
      "          24       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.99       835\n",
      "   macro avg       0.83      0.84      0.84       835\n",
      "weighted avg       0.99      0.99      0.99       835\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lates\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lates\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lates\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lates\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lates\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Lates\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "GBT = GradientBoostingClassifier(n_estimators=5000,\n",
    "                                       learning_rate=0.01,\n",
    "                                       max_depth=3,\n",
    "                                       subsample=0.5,\n",
    "                                       validation_fraction=0.1,\n",
    "                                       n_iter_no_change=20,\n",
    "                                       max_features='log2'\n",
    "                                      ).fit(x_train,y_train)\n",
    "\n",
    "GBT.score(x_test,y_test)\n",
    "\n",
    "predictions = GBT.predict(x_test)\n",
    "print(GBT.feature_names_in_)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Generally, the model works sufficiently well with classifing rings with large support size (as expected). Smaller support sizes still have decent performance with predictions becoming unreliable at lower support sizes (< 5). Since our training and test sets change as we re-run the notebook, we see a variance in the f1-score. Generally, we see an f1-score between 85-96 meaning our model works well. A drawback is our data set size is small at 41k rows. Future studies would benefit from increasing the sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regularize, run, and fit the model\n",
    "### We already split the data into the training and test set which well use here.\n",
    "\n",
    "### We use scikit-learn's pipeline to scale the data as SGD is sensitive to feature scaling.\n",
    "### -  **Regularization:** L2 - Default of SGD Regressor in Scikit learn. Well keep L2 since we have a low amount of features and do not want to shrink any coefficients to zero.\n",
    "### -  **Loss Function:** Squared error - I want to be sensititve to any outliers in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Actual: 8 - Prediction: 7.9891741751514385\n",
      "Actual: 7 - Prediction: 7.008700008282071\n",
      "Actual: 15 - Prediction: 15.012467060954823\n",
      "Actual: 7 - Prediction: 7.0124624501370345\n",
      "Actual: 16 - Prediction: 16.004053660432227\n",
      "Actual: 10 - Prediction: 9.999869158558493\n",
      "Score: 0.9999715582142357\n"
     ]
    }
   ],
   "source": [
    "reg = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "reg_predictions = reg.predict(x_test)\n",
    "\n",
    "## Prettier the data to compare actual vs prediction of the first 6 items.\n",
    "i = 0\n",
    "pred_arr = []\n",
    "actual_arr = []\n",
    "for pred in reg_predictions:\n",
    "    pred_arr.append(pred)\n",
    "    i += 1\n",
    "    if i > 6:\n",
    "        break\n",
    "print(\"-----------------------------------------------------\")\n",
    "i = 0\n",
    "for act in y_test:\n",
    "    actual_arr.append(act)\n",
    "    i += 1\n",
    "    if i > 6:\n",
    "        break\n",
    "\n",
    "for x in range(6):\n",
    "    print(\"Actual: \" + str(actual_arr[x]) + \" - Prediction: \" + str(pred_arr[x]))\n",
    "\n",
    "\n",
    "print(\"Score: \" + str(reg.score(x_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Our regression model predicts Ring count very well. There is little varience between the actual vs predicted value. Similar to the gradient boosted trees, a drawback here is our sample size."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "975625868c44c71bd9e0b31fd9d84411056ff96dd2417335527697104e106896"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
